{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This sript is based on the script on 20160603\n",
    "* The purpose of this script today is to study the combination of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import graphlab\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# datetime.date format: year, month, day\n",
    "def date_to_day(date):\n",
    "    date_list = date.strip().split('-')\n",
    "    return datetime.date(int(date_list[0]),int(date_list[1]),int(date_list[2])).weekday() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define MAPE evaluation function\n",
    "def mape(result, result_predicted):\n",
    "    count = 0\n",
    "    sum = 0\n",
    "    for (item_1, item_2) in zip(result, result_predicted):\n",
    "        if item_1 > 0:\n",
    "            count = count + 1\n",
    "            sum = sum + math.fabs((item_1 - item_2)/item_1)\n",
    "    return (sum, count, sum/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define post_prediction_modification to predicted data\n",
    "# set all the predicted gap that is less than 1 to 1\n",
    "def prediction_modification(prediction):\n",
    "    vect = prediction\n",
    "    for i in range(len(vect)):\n",
    "        if vect[i] < 1.0:\n",
    "            vect[i] = 1.0\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] graphlab.connect.main:  ========================================\n",
      "GraphLab Create requires a license to use. To get a non-commercial  license for academic use only, visit https://turi.com/register.\n",
      "=================================================\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidProductKey",
     "evalue": "Product key not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidProductKey\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1c2d04aa14bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# SFrame.read_csv function to read csv files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data-all_training.csv\"\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mcolumn_type_hints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_test_set_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data-all_test_set_1.csv\"\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mcolumn_type_hints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\dato-env\\lib\\site-packages\\graphlab\\data_structures\\sframe.pyc\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(cls, url, delimiter, header, error_bad_lines, comment_char, escape_char, double_quote, quote_char, skip_initial_space, column_type_hints, na_values, line_terminator, usecols, nrows, skiprows, verbose, nrows_to_infer, **kwargs)\u001b[0m\n\u001b[0;32m   1623\u001b[0m                                   \u001b[0mstore_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m                                   \u001b[0mnrows_to_infer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows_to_infer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m                                   **kwargs)[0]\n\u001b[0m\u001b[0;32m   1626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\dato-env\\lib\\site-packages\\graphlab\\data_structures\\sframe.pyc\u001b[0m in \u001b[0;36m_read_csv_impl\u001b[1;34m(cls, url, delimiter, header, error_bad_lines, comment_char, escape_char, double_quote, quote_char, skip_initial_space, column_type_hints, na_values, line_terminator, usecols, nrows, skiprows, verbose, store_errors, nrows_to_infer, **kwargs)\u001b[0m\n\u001b[0;32m   1086\u001b[0m           \u001b[0mparsing_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"row_limit\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[0mproxy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnitySFrameProxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglconnect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_client\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m         \u001b[0minternal_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_internal_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\dato-env\\lib\\site-packages\\graphlab\\connect\\main.pyc\u001b[0m in \u001b[0;36mget_client\u001b[1;34m()\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mis_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mENGINE_START_ERROR_MESSAGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__CLIENT__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\envs\\dato-env\\lib\\site-packages\\graphlab\\connect\\main.pyc\u001b[0m in \u001b[0;36mlaunch\u001b[1;34m(server_addr, server_bin, server_log, auth_token, server_public_key)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_log_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# start the client\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidProductKey\u001b[0m: Product key not found."
     ]
    }
   ],
   "source": [
    "# SFrame.read_csv function to read csv files\n",
    "data_training = graphlab.SFrame.read_csv(\"data-all_training.csv\", \\\n",
    "                                        column_type_hints=[str,str,long,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           float,float,float,float,float,str,str,str,str,long,long,\\\n",
    "                                                           long,long,float,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           long,long,long,long,long,long,long,long,long,long,long,long])\n",
    "data_test_set_1 = graphlab.SFrame.read_csv(\"data-all_test_set_1.csv\", \\\n",
    "                                          column_type_hints=[str,str,long,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           float,float,float,float,float,str,str,str,str,long,long,\\\n",
    "                                                           long,long,float,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           long,long,long,long,long,long,long,long,long,long,long,long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_training['day_of_week'] = data_training['date'].apply(lambda x: str(date_to_day(x)))\n",
    "data_test_set_1['day_of_week'] = data_test_set_1['date'].apply(lambda x: str(date_to_day(x)))\n",
    "\n",
    "data_training['gap_delta'] = data_training['gap_t(j)'] - data_training['gap_t(j-1)']\n",
    "data_training['gap_delta_1'] = data_training['gap_t(j-1)'] - data_training['gap_t(j-2)']\n",
    "data_training['gap_delta_2'] = data_training['gap_t(j-2)'] - data_training['gap_t(j-3)']\n",
    "data_training['gap_delta_3'] = data_training['gap_t(j-1)'] - data_training['gap_t(j-3)']\n",
    "\n",
    "data_test_set_1['gap_delta'] = data_test_set_1['gap_t(j)'] - data_test_set_1['gap_t(j-1)']\n",
    "data_test_set_1['gap_delta_1'] = data_test_set_1['gap_t(j-1)'] - data_test_set_1['gap_t(j-2)']\n",
    "data_test_set_1['gap_delta_2'] = data_test_set_1['gap_t(j-2)'] - data_test_set_1['gap_t(j-3)']\n",
    "data_test_set_1['gap_delta_3'] = data_test_set_1['gap_t(j-1)'] - data_test_set_1['gap_t(j-3)']\n",
    "\n",
    "# delete data at time_slot_id 1, 2 and 3\n",
    "data_training = data_training[(data_training['time_slot_id'] > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_training_training, data_training_validation = data_training.random_split(.9, seed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['start_district_id', 'time_slot_id', 'gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)', 'gap_averaged',\n",
    "            'gap_delta_1','gap_delta_2','gap_delta_3',\n",
    "            'order_t(j-1)', 'order_t(j-2)', 'order_t(j-3)', 'order_averaged', 'price_avg_t(j-1)', 'price_avg_t(j-2)',\n",
    "            'price_avg_t(j-3)', 'weather_t(j)', 'weather_t(j-1)', 'weather_t(j-2)', 'weather_t(j-3)', \n",
    "            'pm_t(j)','pm_t(j-1)','pm_t(j-2)','pm_t(j-3)','pm_avg', 'tj_1_j', 'tj_2_j','tj_3_j','tj_4_j',\n",
    "            'tj_1_j_1', 'tj_2_j_1','tj_3_j_1','tj_4_j_1', 'tj_1_j_2', 'tj_2_j_2','tj_3_j_2','tj_4_j_2',\n",
    "            'tj_1_j_3', 'tj_2_j_3','tj_3_j_3','tj_4_j_3','day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_numpy_training = data_training_training[features].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(feature_numpy_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_numpy_training = data_training_training['gap_delta'].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_numpy_validation = data_training_validation[features].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_numpy_validation = data_training_validation['gap_delta'].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least Absolute Deviation (LAD) regression\n",
    "\n",
    "# Fit regression model\n",
    "params = {'n_estimators':100, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'quantile', 'alpha': 0.5}\n",
    "model_lad = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "model_lad.fit(feature_numpy_training, target_numpy_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least Squares (LS) regression\n",
    "\n",
    "# Fit regression model\n",
    "params = {'n_estimators':1, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "model_ls = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "model_ls.fit(feature_numpy_training, target_numpy_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graphlab model\n",
    "model_gl = graphlab.boosted_trees_regression.create(data_training_training, features=features, target='gap_delta', \n",
    "                                                    max_iterations = 100,\n",
    "                                                    max_depth = 9, random_seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LAD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data_training_validation['gap_t(j-1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(model_lad.predict(feature_numpy_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_prediction_lad = (model_lad.predict(feature_numpy_validation) + data_training_validation['gap_t(j-1)'].to_numpy().astype(float)).tolist()\n",
    "#print validation_prediction[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_target = (target_numpy_validation + data_training_validation['gap_t(j-1)'].to_numpy().astype(float)).tolist()\n",
    "#print validation_target[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_comparison = graphlab.SFrame()\n",
    "model_comparison['target_value'] = validation_target\n",
    "model_comparison['model_lad_unmodified'] = validation_prediction_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction_modification\n",
    "validation_prediction_lad_modified = prediction_modification(validation_prediction_lad)\n",
    "#print validation_prediction_modified[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_lad) = mape(validation_target,validation_prediction_lad_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_lad = %f\" %mape_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_lad = np.sqrt(mean_squared_error(validation_target,validation_prediction_lad_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_lad = %f\" %rmse_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_lad_modified'] = validation_prediction_lad_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_ls = model_ls.predict(feature_numpy_validation).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_ls_unmodified'] = validation_prediction_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_ls_modified = prediction_modification(validation_prediction_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_ls) = mape(validation_target,validation_prediction_ls_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_ls = %f\" %mape_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_ls = np.sqrt(mean_squared_error(validation_target,validation_prediction_ls_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_ls = %f\" %rmse_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_comparison['model_ls_modified'] = validation_prediction_ls_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graphlab model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_prediction_gl = list(model_gl.predict(data_training_validation) + data_training_validation['gap_t(j-1)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_gl_unmodified'] = validation_prediction_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_prediction_gl_modified = prediction_modification(validation_prediction_gl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_gl) = mape(validation_target,validation_prediction_gl_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_gl = %f\" %mape_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_gl = np.sqrt(mean_squared_error(validation_target,validation_prediction_gl_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_gl = %f\" %rmse_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_gl_modified'] = validation_prediction_gl_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_comparison.export_csv(\"model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New boosting: integrate Graphlab rmse model and Scikit lad model\n",
    "* Low rmse is used to fit big gap numbers\n",
    "* Low lad is used to fit most of the numbers (here small gap numbers)\n",
    "* Ask machine to learn how to choose different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_boosting = graphlab.SFrame()\n",
    "data_boosting = data_training_validation['start_district_id', 'time_slot_id', \n",
    "                                         'gap_t(j)', 'gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)', 'day_of_week']\n",
    "data_boosting['gl_ls_predicted'] = validation_prediction_gl_modified\n",
    "data_boosting['scikit_lad_predicted'] = validation_prediction_lad_modified\n",
    "features_boosting = ['gl_ls_predicted', 'scikit_lad_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators':100, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'quantile', 'alpha': 0.5}\n",
    "model_boosting = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "feature_numpy_boosting = data_boosting[features_boosting].to_numpy().astype(float)\n",
    "target_numpy_boosting = data_boosting['gap_t(j)'].to_numpy().astype(float)\n",
    "\n",
    "model_boosting.fit(feature_numpy_boosting, target_numpy_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_boosting = model_boosting.predict(feature_numpy_boosting).tolist()\n",
    "#validation_prediction_boosting = list(model_boosting.predict(data_training_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_boosting_modified = prediction_modification(validation_prediction_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_boosting) = mape(validation_target,validation_prediction_boosting_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_boosting = np.sqrt(mean_squared_error(validation_target,validation_prediction_boosting_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_boosting = %f\" %mape_boosting\n",
    "print \"rmse_boosting = %f\" %rmse_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_boosting['prediction_boosting'] = validation_prediction_boosting\n",
    "data_boosting['gap_t(j)','gl_ls_predicted','scikit_lad_predicted','prediction_boosting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_boosting['gap_t(j)','gl_ls_predicted','scikit_lad_predicted','prediction_boosting'].print_rows(num_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search for threhold\n",
    "mape_smallest = 1\n",
    "i_corresponding = 1\n",
    "for i in range(1, int(max(validation_prediction_gl_modified)) + 1):\n",
    "    prediction_conditional_combination = []\n",
    "    for j in range(len(validation_prediction_gl_modified)):\n",
    "        if validation_prediction_gl_modified[j] >= i:\n",
    "            prediction_conditional_combination.append(validation_prediction_gl_modified[j])\n",
    "        else:\n",
    "            prediction_conditional_combination.append(validation_prediction_lad_modified[j])\n",
    "    (sum, count, mape_conditional_combination) = mape(validation_target, prediction_conditional_combination)\n",
    "    if mape_conditional_combination < mape_smallest:\n",
    "        mape_smallest = mape_conditional_combination\n",
    "        i_corresponding = i\n",
    "print mape_smallest\n",
    "print i_corresponding\n",
    "\n",
    "prediction_conditional_combination = []\n",
    "for j in range(len(validation_prediction_gl_modified)):\n",
    "    if validation_prediction_gl_modified[j] >= i_corresponding:\n",
    "        prediction_conditional_combination.append(validation_prediction_gl_modified[j])\n",
    "    else:\n",
    "        prediction_conditional_combination.append(validation_prediction_lad_modified[j])\n",
    "    \n",
    "data_boosting['prediction_conditional_combination'] = prediction_conditional_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_boosting['gap_t(j)','gl_ls_predicted','scikit_lad_predicted','prediction_boosting', 'prediction_conditional_combination']\\\n",
    ".export_csv(\"model_comparison_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_items = []\n",
    "fhand = open(\"read_me_1.txt\")\n",
    "for line in fhand:\n",
    "    line_splitted = line.strip().split('-')\n",
    "    prediction_items.append(((line_splitted[0] + '-' + line_splitted[1] + '-' + line_splitted[2]), line_splitted[3]))\n",
    "fhand.close()\n",
    "#prediction_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test_set_1_filtered = graphlab.SFrame()\n",
    "for (date, time_slot_id) in prediction_items:\n",
    "    data_test_set_1_filtered = data_test_set_1_filtered.append(\n",
    "    data_test_set_1[(data_test_set_1['date'] == date) & (data_test_set_1['time_slot_id'] == int(time_slot_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_numpy_test = data_test_set_1_filtered[features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_prediction = model.predict(feature_numpy_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_prediction_modified = prediction_modification(test_prediction)\n",
    "\n",
    "# test_prediction_modified[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_set_1_filtered['prediction'] = test_prediction_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_test_set_1_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(result, filename='submission.txt'):\n",
    "    output_file = open(filename,'w')\n",
    "    for row in data_test_set_1_filtered:\n",
    "        output_file.write(str(row['start_district_id']) + ',' + row['date'] + '-' \\\n",
    "                          + str(row['time_slot_id']) + ',' + str(row['prediction']) + '\\n')\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(data_test_set_1_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
