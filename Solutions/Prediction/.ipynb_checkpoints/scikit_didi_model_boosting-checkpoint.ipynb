{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This sript is based on the script on 20160603\n",
    "* The purpose of this script today is to study the combination of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import graphlab\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# datetime.date format: year, month, day\n",
    "def date_to_day(date):\n",
    "    date_list = date.strip().split('-')\n",
    "    return datetime.date(int(date_list[0]),int(date_list[1]),int(date_list[2])).weekday() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define MAPE evaluation function\n",
    "def mape(result, result_predicted):\n",
    "    count = 0\n",
    "    sum = 0\n",
    "    for (item_1, item_2) in zip(result, result_predicted):\n",
    "        if item_1 > 0:\n",
    "            count = count + 1\n",
    "            sum = sum + math.fabs((item_1 - item_2)/item_1)\n",
    "    return (sum, count, sum/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define post_prediction_modification to predicted data\n",
    "# set all the predicted gap that is less than 1 to 1\n",
    "def prediction_modification(prediction):\n",
    "    vect = prediction\n",
    "    for i in range(len(vect)):\n",
    "        if vect[i] < 1.0:\n",
    "            vect[i] = 1.0\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Marine\\AppData\\Local\\Temp\\graphlab_server_1478495358.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to lei.mao@duke.edu and will expire on November 21, 2016.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\Machine Learning\\Di-Tech_Challenge\\GitHub_Backup\\Di-Tech_Algorithm_Challenge_2016\\Solutions\\Prediction\\data-all_training.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\Machine Learning\\Di-Tech_Challenge\\GitHub_Backup\\Di-Tech_Algorithm_Challenge_2016\\Solutions\\Prediction\\data-all_training.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 199584 lines in 1.15207 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 199584 lines in 1.15207 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\Machine Learning\\Di-Tech_Challenge\\GitHub_Backup\\Di-Tech_Algorithm_Challenge_2016\\Solutions\\Prediction\\data-all_test_set_1.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\Machine Learning\\Di-Tech_Challenge\\GitHub_Backup\\Di-Tech_Algorithm_Challenge_2016\\Solutions\\Prediction\\data-all_test_set_1.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 47520 lines in 0.249014 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 47520 lines in 0.249014 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SFrame.read_csv function to read csv files\n",
    "data_training = graphlab.SFrame.read_csv(\"data-all_training.csv\", \\\n",
    "                                        column_type_hints=[str,str,long,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           float,float,float,float,float,str,str,str,str,long,long,\\\n",
    "                                                           long,long,float,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           long,long,long,long,long,long,long,long,long,long,long,long])\n",
    "data_test_set_1 = graphlab.SFrame.read_csv(\"data-all_test_set_1.csv\", \\\n",
    "                                          column_type_hints=[str,str,long,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           float,float,float,float,float,str,str,str,str,long,long,\\\n",
    "                                                           long,long,float,long,long,long,long,float,long,long,long,long,\\\n",
    "                                                           long,long,long,long,long,long,long,long,long,long,long,long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_training['day_of_week'] = data_training['date'].apply(lambda x: str(date_to_day(x)))\n",
    "data_test_set_1['day_of_week'] = data_test_set_1['date'].apply(lambda x: str(date_to_day(x)))\n",
    "\n",
    "data_training['gap_delta'] = data_training['gap_t(j)'] - data_training['gap_t(j-1)']\n",
    "data_training['gap_delta_1'] = data_training['gap_t(j-1)'] - data_training['gap_t(j-2)']\n",
    "data_training['gap_delta_2'] = data_training['gap_t(j-2)'] - data_training['gap_t(j-3)']\n",
    "data_training['gap_delta_3'] = data_training['gap_t(j-1)'] - data_training['gap_t(j-3)']\n",
    "\n",
    "\n",
    "data_test_set_1['gap_delta_1'] = data_test_set_1['gap_t(j-1)'] - data_test_set_1['gap_t(j-2)']\n",
    "data_test_set_1['gap_delta_2'] = data_test_set_1['gap_t(j-2)'] - data_test_set_1['gap_t(j-3)']\n",
    "data_test_set_1['gap_delta_3'] = data_test_set_1['gap_t(j-1)'] - data_test_set_1['gap_t(j-3)']\n",
    "\n",
    "\n",
    "data_training['log_gap_t(j)'] = data_training['gap_t(j)'].apply(lambda x: math.log10(x+1.0))\n",
    "data_training['log_gap_t(j-1)'] = data_training['gap_t(j-1)'].apply(lambda x: math.log10(x+1.0))\n",
    "data_training['log_gap_t(j-2)'] = data_training['gap_t(j-2)'].apply(lambda x: math.log10(x+1.0))\n",
    "data_training['log_gap_t(j-3)'] = data_training['gap_t(j-3)'].apply(lambda x: math.log10(x+1.0))\n",
    "\n",
    "\n",
    "data_test_set_1['log_gap_t(j-1)'] = data_test_set_1['gap_t(j-1)'].apply(lambda x: math.log10(x+1.0))\n",
    "data_test_set_1['log_gap_t(j-2)'] = data_test_set_1['gap_t(j-2)'].apply(lambda x: math.log10(x+1.0))\n",
    "data_test_set_1['log_gap_t(j-3)'] = data_test_set_1['gap_t(j-3)'].apply(lambda x: math.log10(x+1.0))\n",
    "\n",
    "\n",
    "# delete data at time_slot_id 1, 2 and 3\n",
    "data_training = data_training[(data_training['time_slot_id'] > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_training_training, data_training_validation = data_training.random_split(.9, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['start_district_id', 'time_slot_id', 'gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)', 'gap_averaged',\n",
    "            'gap_delta_1','gap_delta_2','gap_delta_3',\n",
    "            'log_gap_t(j-1)','log_gap_t(j-2)','log_gap_t(j-3)',\n",
    "            'order_t(j-1)', 'order_t(j-2)', 'order_t(j-3)', 'order_averaged', 'price_avg_t(j-1)', 'price_avg_t(j-2)',\n",
    "            'price_avg_t(j-3)', 'weather_t(j)', 'weather_t(j-1)', 'weather_t(j-2)', 'weather_t(j-3)', \n",
    "            'pm_t(j)','pm_t(j-1)','pm_t(j-2)','pm_t(j-3)','pm_avg', 'tj_1_j', 'tj_2_j','tj_3_j','tj_4_j',\n",
    "            'tj_1_j_1', 'tj_2_j_1','tj_3_j_1','tj_4_j_1', 'tj_1_j_2', 'tj_2_j_2','tj_3_j_2','tj_4_j_2',\n",
    "            'tj_1_j_3', 'tj_2_j_3','tj_3_j_3','tj_4_j_3','day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['start_district_id', 'time_slot_id',\n",
    "            'log_gap_t(j-1)','log_gap_t(j-2)','log_gap_t(j-3)',\n",
    "            'order_t(j-1)', 'order_t(j-2)', 'order_t(j-3)', 'order_averaged', 'price_avg_t(j-1)', 'price_avg_t(j-2)',\n",
    "            'price_avg_t(j-3)', 'weather_t(j)', 'weather_t(j-1)', 'weather_t(j-2)', 'weather_t(j-3)', \n",
    "            'pm_t(j)','pm_t(j-1)','pm_t(j-2)','pm_t(j-3)','pm_avg', 'tj_1_j', 'tj_2_j','tj_3_j','tj_4_j',\n",
    "            'tj_1_j_1', 'tj_2_j_1','tj_3_j_1','tj_4_j_1', 'tj_1_j_2', 'tj_2_j_2','tj_3_j_2','tj_4_j_2',\n",
    "            'tj_1_j_3', 'tj_2_j_3','tj_3_j_3','tj_4_j_3','day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_numpy_training = data_training_training[features].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_numpy_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_numpy_training = data_training_training['log_gap_t(j)'].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_numpy_validation = data_training_validation[features].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_numpy_validation = data_training_validation['log_gap_t(j)'].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Explore hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# define parameters to search\\n\\nn_estimators = [5,10,20,30,40,50,60,70,80,90,100,150,200,300,400,500]\\nmax_depth = [2,3,4,5,6,7,8]\\nmin_samples_split = [1,2,3,4]\\n\\nn_estimators = [5,10]\\nmax_depth = [2,3]\\nmin_samples_split = [1,2]\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# define parameters to search\n",
    "\n",
    "n_estimators = [5,10,20,30,40,50,60,70,80,90,100,150,200,300,400,500]\n",
    "max_depth = [2,3,4,5,6,7,8]\n",
    "min_samples_split = [1,2,3,4]\n",
    "\n",
    "n_estimators = [5,10]\n",
    "max_depth = [2,3]\n",
    "min_samples_split = [1,2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noutput_file = open(\"hyperparamters_test_result\",\\'w\\')\\noutput_file.write(\"n_estimators,max_depth,min_samples_split,mae,rmse\\n\")\\noutput_file.close()\\n\\nfor i in range(len(n_estimators)):\\n    for j in range(len(max_depth)):\\n        for k in range(len(min_samples_split)):\\n            print i, j, k\\n            params = {\\'n_estimators\\':n_estimators[i], \\'max_depth\\': max_depth[j], \\'min_samples_split\\': min_samples_split[k], \\n                      \\'verbose\\': False, \\'learning_rate\\': 0.01, \\'loss\\': \\'quantile\\', \\'alpha\\': 0.5}\\n            model = ensemble.GradientBoostingRegressor(**params)\\n            model.fit(feature_numpy_training, target_numpy_training)\\n            validation_prediction = model.predict(feature_numpy_validation).tolist()\\n            validation_target = target_numpy_validation.tolist()\\n            (sum, count, mae) = mape(validation_target,validation_prediction)\\n            rmse = np.sqrt(mean_squared_error(validation_target,validation_prediction))\\n            output_file = open(\"hyperparamters_test_result\",\\'a\\')\\n            output_file.write(str(n_estimators[i]) + \\',\\' + str(max_depth[j]) + \\',\\' + str(min_samples_split[k]) +                               \\',\\' + str(mae) + \\',\\' + str(rmse) + \\'\\n\\')\\n            output_file.close()\\n            \\n '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "output_file = open(\"hyperparamters_test_result\",'w')\n",
    "output_file.write(\"n_estimators,max_depth,min_samples_split,mae,rmse\\n\")\n",
    "output_file.close()\n",
    "\n",
    "for i in range(len(n_estimators)):\n",
    "    for j in range(len(max_depth)):\n",
    "        for k in range(len(min_samples_split)):\n",
    "            print i, j, k\n",
    "            params = {'n_estimators':n_estimators[i], 'max_depth': max_depth[j], 'min_samples_split': min_samples_split[k], \n",
    "                      'verbose': False, 'learning_rate': 0.01, 'loss': 'quantile', 'alpha': 0.5}\n",
    "            model = ensemble.GradientBoostingRegressor(**params)\n",
    "            model.fit(feature_numpy_training, target_numpy_training)\n",
    "            validation_prediction = model.predict(feature_numpy_validation).tolist()\n",
    "            validation_target = target_numpy_validation.tolist()\n",
    "            (sum, count, mae) = mape(validation_target,validation_prediction)\n",
    "            rmse = np.sqrt(mean_squared_error(validation_target,validation_prediction))\n",
    "            output_file = open(\"hyperparamters_test_result\",'a')\n",
    "            output_file.write(str(n_estimators[i]) + ',' + str(max_depth[j]) + ',' + str(min_samples_split[k]) + \\\n",
    "                              ',' + str(mae) + ',' + str(rmse) + '\\n')\n",
    "            output_file.close()\n",
    "            \n",
    " '''           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0329            2.29m\n",
      "         2           0.0331            2.31m\n",
      "         3           0.0331            2.33m\n",
      "         4           0.0331            2.32m\n",
      "         5           0.0331            2.30m\n",
      "         6           0.0331            2.27m\n",
      "         7           0.0331            2.24m\n",
      "         8           0.0331            2.21m\n",
      "         9           0.0332            2.18m\n",
      "        10           0.0332            2.15m\n",
      "        20           0.0333            1.92m\n",
      "        30           0.0330            1.67m\n",
      "        40           0.0324            1.43m\n",
      "        50           0.0320            1.19m\n"
     ]
    }
   ],
   "source": [
    "# Least Absolute Deviation (LAD) regression\n",
    "\n",
    "# Fit regression model\n",
    "params = {'n_estimators':100, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'quantile', 'alpha': 0.5}\n",
    "model_lad = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "model_lad.fit(feature_numpy_training, target_numpy_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least Squares (LS) regression\n",
    "\n",
    "# Fit regression model\n",
    "params = {'n_estimators':1, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "model_ls = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "model_ls.fit(feature_numpy_training, target_numpy_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graphlab model\n",
    "model_gl = graphlab.boosted_trees_regression.create(data_training_training, features=features, target='log_gap_t(j)', \n",
    "                                                    max_iterations = 100,\n",
    "                                                    max_depth = 9, random_seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict gap_delta to predict gap\n",
    "gap_delta_numpy_training = data_training_training['gap_delta'].to_numpy().astype(float)\n",
    "gap_delta_numpy_validation = data_training_validation['gap_delta'].to_numpy().astype(float)\n",
    "\n",
    "\n",
    "# Least Absolute Deviation (LAD) regression\n",
    "\n",
    "# Fit regression model\n",
    "params = {'n_estimators':100, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'quantile', 'alpha': 0.5}\n",
    "model_delta_lad = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "model_delta_lad.fit(feature_numpy_training, gap_delta_numpy_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LAD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "validation_prediction_lad_temp = model_lad.predict(feature_numpy_validation).tolist()\n",
    "validation_prediction_lad = [math.pow(10,i) - 1.0 for i in validation_prediction_lad_temp]\n",
    "#print validation_prediction[0:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_target = list(data_training_validation['gap_t(j)'])\n",
    "#print validation_target[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_comparison = graphlab.SFrame()\n",
    "model_comparison['target_value'] = validation_target\n",
    "model_comparison['model_lad_unmodified'] = validation_prediction_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction_modification\n",
    "validation_prediction_lad_modified = prediction_modification(validation_prediction_lad)\n",
    "#print validation_prediction_modified[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_lad) = mape(validation_target,validation_prediction_lad_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_lad = %f\" %mape_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse_lad = np.sqrt(mean_squared_error(validation_target,validation_prediction_lad_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_lad = %f\" %rmse_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_lad_modified'] = validation_prediction_lad_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_ls = model_ls.predict(feature_numpy_validation).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_comparison['model_ls_unmodified'] = validation_prediction_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_ls_modified = prediction_modification(validation_prediction_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_ls) = mape(validation_target,validation_prediction_ls_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_ls = %f\" %mape_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_ls = np.sqrt(mean_squared_error(validation_target,validation_prediction_ls_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_ls = %f\" %rmse_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#model_comparison['model_ls_modified'] = validation_prediction_ls_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graphlab model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_prediction_gl_temp = list(model_gl.predict(data_training_validation))\n",
    "\n",
    "validation_prediction_gl = [math.pow(10,i) - 1.0 for i in validation_prediction_gl_temp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_gl_unmodified'] = validation_prediction_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_prediction_gl_modified = prediction_modification(validation_prediction_gl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_gl) = mape(validation_target,validation_prediction_gl_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_gl = %f\" %mape_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_gl = np.sqrt(mean_squared_error(validation_target,validation_prediction_gl_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_gl = %f\" %rmse_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_comparison['model_gl_modified'] = validation_prediction_gl_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict gap_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_delta_lad = (model_delta_lad.predict(feature_numpy_validation) + data_training_validation['gap_t(j-1)'].to_numpy().astype(float)).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_delta_lad_unmodified'] = validation_prediction_delta_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_delta_modified = prediction_modification(validation_prediction_delta_lad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_delta_lad) = mape(validation_target,validation_prediction_delta_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_delta_lad = %f\" %mape_delta_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_delta_lad = np.sqrt(mean_squared_error(validation_target,validation_prediction_delta_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"rmse_delta_lad = %f\" %rmse_delta_lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_comparison['model_delta_lad_modified'] = validation_prediction_delta_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_comparison.export_csv(\"model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New boosting: integrate Graphlab rmse model and Scikit lad model\n",
    "* Low rmse is used to fit big gap numbers\n",
    "* Low lad is used to fit most of the numbers (here small gap numbers)\n",
    "* Ask machine to learn how to choose different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_boosting = graphlab.SFrame()\n",
    "data_boosting = data_training_validation['start_district_id', 'time_slot_id', 'gap_delta_1','gap_delta_2','gap_delta_3',\n",
    "                                         'gap_t(j)', 'gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)', 'day_of_week']\n",
    "data_boosting['gl_ls_predicted'] = validation_prediction_gl_modified\n",
    "data_boosting['scikit_lad_predicted'] = validation_prediction_lad_modified\n",
    "data_boosting['scikit_lad_predicted_delta_method'] = validation_prediction_delta_modified\n",
    "\n",
    "data_boosting['S1'] = data_boosting['gl_ls_predicted'] - data_boosting['scikit_lad_predicted']\n",
    "data_boosting['S2'] = data_boosting['gl_ls_predicted'] - data_boosting['scikit_lad_predicted_delta_method']\n",
    "data_boosting['S3'] = data_boosting['scikit_lad_predicted'] - data_boosting['scikit_lad_predicted_delta_method']\n",
    "\n",
    "data_boosting['D1'] = data_boosting['gl_ls_predicted'] / data_boosting['scikit_lad_predicted']\n",
    "data_boosting['D2'] = data_boosting['gl_ls_predicted'] / data_boosting['scikit_lad_predicted_delta_method']\n",
    "data_boosting['D3'] = data_boosting['scikit_lad_predicted'] / data_boosting['scikit_lad_predicted_delta_method']\n",
    "\n",
    "features_boosting = ['time_slot_id','gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)','gap_delta_1','gap_delta_2','gap_delta_3',\n",
    "                     'S1','S2','S3','D1','D2','D3',\n",
    "                     'gl_ls_predicted', 'scikit_lad_predicted', 'scikit_lad_predicted_delta_method']\n",
    "\n",
    "data_boosting_training, data_boosting_validation = data_boosting.random_split(.9, seed=1)\n",
    "#data_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators':100, 'max_depth': 4, 'min_samples_split': 1, 'verbose': True,\n",
    "          'learning_rate': 0.01, 'loss': 'quantile', 'alpha': 0.5}\n",
    "model_boosting = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "feature_numpy_boosting_training = data_boosting_training[features_boosting].to_numpy().astype(float)\n",
    "target_numpy_boosting_training = data_boosting_training['gap_t(j)'].to_numpy().astype(float)\n",
    "\n",
    "feature_numpy_boosting_validation = data_boosting_validation[features_boosting].to_numpy().astype(float)\n",
    "target_numpy_boosting_validation = data_boosting_validation['gap_t(j)'].to_numpy().astype(float)\n",
    "\n",
    "\n",
    "model_boosting.fit(feature_numpy_boosting_training, target_numpy_boosting_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "model_boosting = graphlab.boosted_trees_regression.create(data_boosting, features = features_boosting, target='gap_t(j)', \n",
    "                                                          max_iterations = 100,\n",
    "                                                          max_depth = 9, random_seed = 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_boosting = model_boosting.predict(feature_numpy_boosting_validation).tolist()\n",
    "#validation_prediction_boosting = list(model_boosting.predict(data_training_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_prediction_boosting_modified = prediction_modification(validation_prediction_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(sum, count, mape_boosting) = mape(target_numpy_boosting_validation,validation_prediction_boosting_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_boosting = np.sqrt(mean_squared_error(target_numpy_boosting_validation,validation_prediction_boosting_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"mape_boosting = %f\" %mape_boosting\n",
    "print \"rmse_boosting = %f\" %rmse_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_boosting_validation['prediction_boosting'] = validation_prediction_boosting\n",
    "data_boosting_validation['gap_t(j)','gap_t(j-1)','gl_ls_predicted','scikit_lad_predicted', \n",
    "                         'scikit_lad_predicted_delta_method', 'prediction_boosting']\n",
    "\n",
    "data_boosting_validation['gap_t(j)','gap_t(j-1)', 'gl_ls_predicted','scikit_lad_predicted', \n",
    "                         'scikit_lad_predicted_delta_method','prediction_boosting'][480:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_boosting_validation['gap_t(j)', 'scikit_lad_predicted_delta_method','prediction_boosting'].print_rows(num_rows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# search for threhold\n",
    "for i in range(1, int(max(validation_prediction_lad_modified)) + 1):\n",
    "    prediction_conditional_combination = []\n",
    "    for j in range(len(validation_prediction_lad_modified)):\n",
    "        if validation_prediction_lad_modified[j] <= i:\n",
    "            prediction_conditional_combination.append(validation_prediction_lad_modified[j])\n",
    "        else:\n",
    "            prediction_conditional_combination.append(validation_prediction_gl_modified[j])\n",
    "    (sum, count, mape_conditional_combination) = mape(validation_target, prediction_conditional_combination)\n",
    "    print mape_conditional_combination\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# search for threhold\n",
    "mape_smallest = 1\n",
    "i_corresponding = 1\n",
    "for i in range(1, int(max(validation_prediction_delta_modified)) + 1):\n",
    "    prediction_conditional_combination = []\n",
    "    for j in range(len(validation_prediction_delta_modified)):\n",
    "        if validation_prediction_delta_modified[j] >= i:\n",
    "            prediction_conditional_combination.append(validation_prediction_delta_modified[j])\n",
    "        else:\n",
    "            prediction_conditional_combination.append(validation_prediction_lad_modified[j])\n",
    "    (sum, count, mape_conditional_combination) = mape(validation_target, prediction_conditional_combination)\n",
    "    if mape_conditional_combination < mape_smallest:\n",
    "        mape_smallest = mape_conditional_combination\n",
    "        i_corresponding = i\n",
    "print mape_smallest\n",
    "print i_corresponding\n",
    "\n",
    "prediction_conditional_combination = []\n",
    "for j in range(len(validation_prediction_delta_modified)):\n",
    "    if validation_prediction_delta_modified[j] >= i_corresponding:\n",
    "        prediction_conditional_combination.append(validation_prediction_delta_modified[j])\n",
    "    else:\n",
    "        prediction_conditional_combination.append(validation_prediction_lad_modified[j])\n",
    "    \n",
    "data_boosting['prediction_conditional_combination'] = prediction_conditional_combination\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "data_boosting['gap_t(j)','gl_ls_predicted','scikit_lad_predicted','prediction_boosting', 'prediction_conditional_combination']\\\n",
    ".export_csv(\"model_comparison_2.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_items = []\n",
    "fhand = open(\"read_me_1.txt\")\n",
    "for line in fhand:\n",
    "    line_splitted = line.strip().split('-')\n",
    "    prediction_items.append(((line_splitted[0] + '-' + line_splitted[1] + '-' + line_splitted[2]), line_splitted[3]))\n",
    "fhand.close()\n",
    "#prediction_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test_set_1_filtered = graphlab.SFrame()\n",
    "for (date, time_slot_id) in prediction_items:\n",
    "    data_test_set_1_filtered = data_test_set_1_filtered.append(\n",
    "    data_test_set_1[(data_test_set_1['date'] == date) & (data_test_set_1['time_slot_id'] == int(time_slot_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_numpy_test = data_test_set_1_filtered[features].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lad model prediction\n",
    "test_prediction_lad_temp_1 = model_lad.predict(feature_numpy_test).tolist()\n",
    "test_prediction_lad_temp_2 = [math.pow(10,i) - 1.0 for i in test_prediction_lad_temp_1]\n",
    "test_prediction_lad = prediction_modification(test_prediction_lad_temp_2)\n",
    "\n",
    "\n",
    "# graphlab model prediction\n",
    "test_prediction_gl_temp_1 = list(model_gl.predict(data_test_set_1_filtered))\n",
    "test_prediction_gl_temp_2 = [math.pow(10,i) - 1.0 for i in test_prediction_gl_temp_1]\n",
    "test_prediction_gl = prediction_modification(test_prediction_gl_temp_2)\n",
    "\n",
    "# gap_delta model prediction\n",
    "test_prediction_delta_lad = prediction_modification\\\n",
    "((model_delta_lad.predict(feature_numpy_test) + data_test_set_1_filtered['gap_t(j-1)'].to_numpy().astype(float)).tolist())\n",
    "\n",
    "\n",
    "test_data_boosting = graphlab.SFrame()\n",
    "test_data_boosting = data_test_set_1_filtered['start_district_id', 'time_slot_id', 'gap_delta_1','gap_delta_2','gap_delta_3',\n",
    "                                              'gap_t(j)', 'gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)', 'day_of_week']\n",
    "\n",
    "test_data_boosting['gl_ls_predicted'] = test_prediction_gl\n",
    "test_data_boosting['scikit_lad_predicted'] = test_prediction_lad\n",
    "test_data_boosting['scikit_lad_predicted_delta_method'] = test_prediction_delta_lad\n",
    "\n",
    "test_data_boosting['S1'] = test_data_boosting['gl_ls_predicted'] - test_data_boosting['scikit_lad_predicted']\n",
    "test_data_boosting['S2'] = test_data_boosting['gl_ls_predicted'] - test_data_boosting['scikit_lad_predicted_delta_method']\n",
    "test_data_boosting['S3'] = test_data_boosting['scikit_lad_predicted'] - test_data_boosting['scikit_lad_predicted_delta_method']\n",
    "\n",
    "test_data_boosting['D1'] = test_data_boosting['gl_ls_predicted'] / test_data_boosting['scikit_lad_predicted']\n",
    "test_data_boosting['D2'] = test_data_boosting['gl_ls_predicted'] / test_data_boosting['scikit_lad_predicted_delta_method']\n",
    "test_data_boosting['D3'] = test_data_boosting['scikit_lad_predicted'] / test_data_boosting['scikit_lad_predicted_delta_method']\n",
    "\n",
    "features_boosting = ['time_slot_id','gap_t(j-1)', 'gap_t(j-2)', 'gap_t(j-3)','gap_delta_1','gap_delta_2','gap_delta_3',\n",
    "                     'S1','S2','S3','D1','D2','D3',\n",
    "                     'gl_ls_predicted', 'scikit_lad_predicted', 'scikit_lad_predicted_delta_method']\n",
    "\n",
    "feature_numpy_boosting_test = test_data_boosting[features_boosting].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction_boosting = model_boosting.predict(feature_numpy_boosting_test).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_prediction_modified = prediction_modification(test_prediction_boosting)\n",
    "\n",
    "# test_prediction_modified[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test_set_1_filtered['prediction'] = test_prediction_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_test_set_1_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(result, filename='submission.txt'):\n",
    "    output_file = open(filename,'w')\n",
    "    for row in data_test_set_1_filtered:\n",
    "        output_file.write(str(row['start_district_id']) + ',' + row['date'] + '-' \\\n",
    "                          + str(row['time_slot_id']) + ',' + str(row['prediction']) + '\\n')\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(data_test_set_1_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
